---
title: "DDoS Attack Mitigation"
output:
  html_document: default
  html_notebook: default
  pdf_document: default
---
```{r setup, echo=FALSE, include=FALSE}

source("ddosm.R")

```

# Overview

TODO: Revise Jain's principles and common mistakes. 

TODO: Outline the rest of the work. 

## Parameters

### Dataset

TODO: Introduce the dataset. 

We used a dataset with 2^24 packets in the detection phase.

### Sensitivity Coefficients

TODO: Explain.

What are our chosen k coefficients? 

Our experiments with tcad_m_levels.py show us candidate values for k, as follows: 

Log2(m) | k     | FPR
--------|-------|-----
14      | 4.125 | 1.7%
16      | 4.500 | 1.6%
18      | 3.625 | 0.0%

### TCAD Traces

TODO: Explain.

[Source: DDoS Mitigation.ipynb, section Finding TCAD Values]

TCAD measurements can be found in the following files: 

  tcad_m_2_14_k_4.125.log
  tcad_m_2_16_k_4.500.log
  tcad_m_2_18_k_3.625.log

## Observation Window Numbers

**Note: When we preinitialize training coefficients, the length of the workload is equal to the length of the detection phase.**

For a detection phase of 2^24 packets we have: 

  2^(24-log2m-2) OWs before the attack,
  2^(24-log2m-1) OWs under attack, 
  2^(24-log2m-2) OWs after the attack.
  
For m=2^14, the detection phase has 2^(24-14)=2^10 windows: 
  
  2^8 OWs pre-attack and post attack,  
  2^9 OWs under attack, 

For m=2^16, 2^8 windows: 

  2^6 OWs pre-attack and post-attack,
  2^7 OWs under attack.
  
For m=2^18, 2^6 windows: 
  
  2^4 OWs pre-attack and post-attack,
  2^5 OWs under attack.
  

# Workload Characterization

## Reading TCAD Trace Files

```{r read_tcad_traces, include=TRUE}

tcad_m14 = read_tcad_trace(tcad_m14_trace)
tcad_m16 = read_tcad_trace(tcad_m16_trace)
tcad_m18 = read_tcad_trace(tcad_m18_trace)

```

## Entropy Overview

```{r entropy_overview, include=TRUE}

title = "Entropy for each Observation Window "

get_plot_tcad(tcad_m14, tcad_m14_k) + labs(title=str_c(title,"(m = 2^14)"))
get_plot_tcad(tcad_m16, tcad_m16_k) + labs(title=str_c(title,"(m = 2^16)"))
get_plot_tcad(tcad_m18, tcad_m18_k) + labs(title=str_c(title,"(m = 2^18)"))

graph_path = "graphs"

ggsave(path=graph_path, filename="entropy_all.svg")

```

## Entropy Under Attack

We have the graph for the entire experiments. Now we need to focus in the attack.

```{r entropy_under_attack, include=TRUE}

title = "Entropy for each Observation Window - Attack Phase "

get_plot_tcad_attack(tcad_m14, tcad_m14_k, log2n, 14) + labs(title=str_c(title,"(m = 2^14)"))
get_plot_tcad_attack(tcad_m16, tcad_m16_k, log2n, 16) + labs(title=str_c(title,"(m = 2^16)"))
get_plot_tcad_attack(tcad_m18, tcad_m18_k, log2n, 18) + labs(title=str_c(title,"(m = 2^18)"))
ggsave(path=graph_path, filename="entropy_attack.svg")


```

# Attack Mitigation

```{r}

summary_all = tibble() 

```


## Loading

```{r}

log2m = as.integer(18)

if (log2m == 14)  {
  pcap_csv = pcap_csv_m14
} else if (log2m == 16) {
  pcap_csv = pcap_csv_m16
} else if (log2m == 18) {
  pcap_csv = pcap_csv_m18
} else {
  stop("Invalid log2m value.")
}

attack_first_ow = attack_first(log2n, log2m) + 2 # Diversion begins at the second OW under attack. 
attack_last_ow = attack_last(log2n, log2m)

packets = read_pcap_csv(log2n, log2m, pcap_csv) %>% filter(ow >= attack_first_ow, ow <= attack_last_ow)



```

## Typical Deltas

For each OW, what are the typical frequency deltas for attack packets? 

```{r typical_deltas, include=TRUE}

deltas = summarize_deltas(log2n, log2m, packets)

dot_size = 2.0

graph_path = str_c("graphs_", log2m)

delta_plot_options = list(
  geom_point(aes(y=diffq1), color="blue4", size=dot_size),
  geom_point(aes(y=diffq2), color="yellow4", size=dot_size),
  geom_point(aes(y=diffq3), color="orangered4", size=dot_size))

deltas %>% 
  ggplot(aes(x=ow, shape=attack)) + delta_plot_options

ggsave(path=graph_path, filename="diffs.svg")

#deltas.m = melt(packets %>% select(ow,attack,diff), id.var = "attack")
#deltas.m %>% ggplot(aes(x=variable, y=value)) + geom_boxplot(aes(fill=attack))


```
It would be cool to plot several box plots. 


## Classification

```{r fn_divert, include=TRUE}

if (log2m == 14) { 
  diff_threshold = 128L
} else if (log2m == 16) {
  diff_threshold = 256L
} else if (log2m == 18) {
  diff_threshold = 256L
} else {
  stop("Invalid log2m value.")
}

divert = function(diff) (diff >= diff_threshold)
packets = packets %>% mutate(diverted=divert(diff)) %>% group_by(ow)

```

## Statistics

Base Stats and Confidence Intervals

Both TPR and FPR are proportions whose values we need to estimate.

Let X be a random variable whose value is 1 when a classification succeeds, and 0 otherwise. Consequently, X follows a a Bernoulli distribution with probability p. We can use our sample to estimate the mean value of p. This sample mean has a sampling error approximately equal to sqrt(p * (1-p) / n), where n is the sample size (the total number of classification events).     

What are the questions?
1. Considering the attack as a whole, what are the TPR and the FPR? 
2. Considering OWs, what are the TPR and the FPR? [This could be a plot]
3. Considering OWs, what is the 95% confidence interval for the mean TPR and FPR?  


```{r fn_stats, include=TRUE}

stats = get_stats(packets, log2n, log2m)

summary = stats %>% 
  summarize(log2m  = log2m,
            t = diff_threshold,
            n = n(),
            t_evil = sum(n_evil),
            t_tp   = sum(n_tp),
            t_good = sum(n_good),
            t_fp   = sum(n_fp)) %>%
  mutate(p_tp = t_tp / t_evil,
         p_fp = t_fp / t_good) %>% 
  mutate(se_tp = sqrt(p_tp * (1 - p_tp) / n),
         se_fp = sqrt(p_fp * (1 - p_fp) / n)) %>% 
  mutate(i95_tp = qnorm(0.975) * se_tp,
         i95_fp = qnorm(0.975) * se_fp) %>%
  mutate(i95_tp_lb = p_tp - i95_tp,
         i95_tp_ub = p_tp + i95_tp,
         i95_fp_lb = p_fp - i95_fp,
         i95_fp_ub = p_fp + i95_fp) %>%
  mutate_if(is.double, funs(round(.,4))) %>%
  select(log2m, t, 
         p_tp, i95_tp_lb, i95_tp_ub, 
         p_fp, i95_fp_lb, i95_fp_ub)

summary_all = bind_rows(summary_all, summary)

summary_all 
  
```

This should be graphed as a function of t. 

## Graphs

It is interesting to observe what happens **over time**, OW after OW. 

```{r classification_graphs, include=TRUE}

graph_marked_good(packets)
graph_marked_evil(packets)
graph_false_negatives(packets)
ggsave(path=graph_path, filename="false_negatives.svg")
graph_false_positives(packets)
ggsave(path=graph_path, filename="false_positives.svg")
graph_results(packets)
ggsave(path=graph_path, filename="results.svg")

```

Adjust scale, add legitimate and attack percentage lines. 

## Address Counts

```{r frequencies}

# graph_options = list(geom_line(), scale_color_manual(values=c("seagreen4", "orangered1")))
# 
# src_distinct = packets %>% group_by(ow, attack, diff) %>% summarize(srcs=n_distinct(src))
# src_distinct %>% ggplot(aes(diff, srcs, color=attack)) + graph_options
# 
# ggsave(path=graph_path, filename="src_delta_distribution.svg")
# 
# dst_distinct = packets %>% group_by(ow, attack, diff) %>% summarize(dsts=n_distinct(dst))
# dst_distinct %>% ggplot(aes(diff, dsts, color=attack)) + graph_options
# 
# ggsave(path=graph_path, filename="dst_delta_distribution.svg")

```


# Discussion 

